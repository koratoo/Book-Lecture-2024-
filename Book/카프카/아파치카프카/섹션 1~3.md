## 목차

### [1장 들어가며](#1장-들어가며)

- [1.1 카프카의 탄생](#11-카프카의-탄생)
- [1.2 빅데이터 파이프라인에서 카프카의 역할](#12-빅데이터-파이프라인에서-카프카의-역할)
- [1.3 데이터 레이크 아키텍처와 카프카의 미래](#13-데이터-레이크-아키텍처와-카프카의-미래)
- [1.4 정리](#14-정리)

### [2장 카프카 빠르게 시작해보기](#2장-카프카-빠르게-시작해보기)

- [2.1 실습용 카프카 브로커 설치](#21-실습용-카프카-브로커-설치)

  - [2.1.1 AWS EC2 인스턴스 발급 및 보안 설정](#211-aws-ec2-인스턴스-발급-및-보안-설정)
  - [2.1.2 인스턴스에 접속하기](#212-인스턴스에-접속하기)
    - [ssh 명령어로 접속하기](#ssh-명령어로-접속하기)
    - [putty로 접속하기](#putty로-접속하기)
  - [2.1.3 인스턴스에 자바 설치](#213-인스턴스에-자바-설치)
  - [2.1.4 주키퍼·카프카 브로커 실행](#214-주키퍼카프카-브로커-실행)
    - [카프카 브로커 힙 메모리 설정](#카프카-브로커-힙-메모리-설정)
    - [카프카 브로커 실행 옵션 설정](#카프카-브로커-실행-옵션-설정)
    - [주키퍼 실행](#주키퍼-실행)
    - [카프카 브로커 실행 및 로그 확인](#카프카-브로커-실행-및-로그-확인)
  - [2.1.5 로컬 컴퓨터에서 카프카와 통신 확인](#215-로컬-컴퓨터에서-카프카와-통신-확인)
    - [테스트 편의를 위한 hosts 설정](#테스트-편의를-위한-hosts-설정)

- [2.2 카프카 커맨드 라인 툴](#22-카프카-커맨드-라인-툴)
  - [2.2.1 kafka-topics.sh](#221-kafka-topicssh)
    - [토픽 생성](#토픽-생성)
    - [토픽 리스트 조회](#토픽-리스트-조회)
    - [토픽 상세 조회](#토픽-상세-조회)
    - [토픽 옵션 수정](#토픽-옵션-수정)
  - [2.2.2 kafka-console-producer.sh](#222-kafka-console-producersh)
  - [2.2.3 kafka-console-consumer.sh](#223-kafka-console-consumersh)
  - [2.2.4 kafka-consumer-groups.sh](#224-kafka-consumer-groupssh)
  - [2.2.5 kafka-verifiable-producer, consumer.sh](#225-kafka-verifiable-producer-consumersh)
  - [2.2.6 kafka-delete-records.sh](#226-kafka-delete-recordssh)
- [2.3 정리](#23-정리)

### [3장 카프카 기본 개념 설명](#3장-카프카-기본-개념-설명)

- [3.1 카프카 브로커 · 클러스터 · 주키퍼](#31-카프카-브로커--클러스터--주키퍼)

  - [데이터 저장, 전송](#데이터-저장-전송)
  - [데이터 복제, 싱크](#데이터-복제-싱크)
  - [컨트롤러(controller)](#컨트롤러controller)
  - [데이터 삭제](#데이터-삭제)
  - [컨슈머 오프셋 저장](#컨슈머-오프셋-저장)
  - [코디네이터(coordinator)](#코디네이터coordinator)

- [3.2 토픽과 파티션](#32-토픽과-파티션)

  - [토픽 이름 제약 조건](#토픽-이름-제약-조건)
  - [의미 있는 토픽 이름 작명 방법](#의미-있는-토픽-이름-작명-방법)

- [3.3 레코드](#33-레코드)

- [3.4 카프카 클라이언트](#34-카프카-클라이언트)

  - [3.4.1 프로듀서 API](#341-프로듀서-api)
    - [카프카 프로듀서 프로젝트 생성](#카프카-프로듀서-프로젝트-생성)
    - [프로듀서 중요 개념](#프로듀서-중요-개념)
    - [프로듀서 주요 옵션](#프로듀서-주요-옵션)
    - [메시지 키를 가진 데이터를 전송하는 프로듀서](#메시지-키를-가진-데이터를-전송하는-프로듀서)
    - [커스텀 파티셔너를 가지는 프로듀서](#커스텀-파티셔너를-가지는-프로듀서)
    - [브로커 정상 전송 여부를 확인하는 프로듀서](#브로커-정상-전송-여부를-확인하는-프로듀서)
  - [3.4.2 컨슈머 API](#342-컨슈머-api)
    - [카프카 컨슈머 프로젝트 생성](#카프카-컨슈머-프로젝트-생성)
    - [컨슈머 중요 개념](#컨슈머-중요-개념)
    - [컨슈머 주요 옵션](#컨슈머-주요-옵션)
    - [동기 오프셋 커밋](#동기-오프셋-커밋)
    - [비동기 오프셋 커밋](#비동기-오프셋-커밋)
    - [리밸런스 리스너를 가진 컨슈머](#리밸런스-리스너를-가진-컨슈머)
    - [파티션 할당 컨슈머](#파티션-할당-컨슈머)
    - [컨슈머에 할당된 파티션 확인 방법](#컨슈머에-할당된-파티션-확인-방법)
    - [컨슈머의 안전한 종료](#컨슈머의-안전한-종료)
  - [3.4.3 어드민 API](#343-어드민-api)
    - [브로커 정보 조회](#브로커-정보-조회)
    - [토픽 정보 조회](#토픽-정보-조회)

- [3.5 카프카 스트림즈](#35-카프카-스트림즈)

  - [3.5.1 스트림즈DSL](#351-스트림즈dsl)
    - [KStream](#kstream)
    - [KTable](#ktable)
    - [GlobalKTable](#globalktable)
    - [스트림즈DSL 주요 옵션](#스트림즈dsl-주요-옵션)
    - [스트림즈DSL - stream(), to()](#스트림즈dsl---stream--to)
    - [스트림즈DSL - filter()](#스트림즈dsl---filter)
    - [스트림즈DSL - KTable과 KStream을 join()](#스트림즈dsl---ktable과-kstream을-join)
    - [스트림즈DSL - GlobalKTable과 KStream을 join()](#스트림즈dsl---globalktable과-kstream을-join)
  - [3.5.2 프로세서 API](#352-프로세서-api)

- [3.6 카프카 커넥트](#36-카프카-커넥트)

  - [커넥트를 실행하는 방법](#커넥트를-실행하는-방법)
  - [단일 모드 커넥트](#단일-모드-커넥트)
  - [분산 모드 커넥트](#분산-모드-커넥트)
  - [3.6.1 소스 커넥터](#361-소스-커넥터)
    - [파일 소스 커넥터 구현](#파일-소스-커넥터-구현)
  - [3.6.2 싱크 커넥터](#362-싱크-커넥터)
    - [파일 싱크 커넥터 구현](#파일-싱크-커넥터-구현)

- [3.7 카프카 미러메이커2](#37-카프카-미러메이커2)

  - [3.7.1 미러메이커2를 활용한 지리적 복제(Geo-Replication)](#371-미러메이커2를-활용한-지리적-복제geo-replication)

- [3.8 정리](#38-정리)

## 1장 들어가며

### 1.1 카프카의 탄생

### 1.2 빅데이터 파이프라인에서 카프카의 역할

### 1.3 데이터 레이크 아키텍처와 카프카의 미래

### 1.4 정리

## 2장 카프카 빠르게 시작해보기

### 2.1 실습용 카프카 브로커 설치

#### 2.1.1 AWS EC2 인스턴스 발급 및 보안 설정

#### 2.1.2 인스턴스에 접속하기

##### ssh 명령어로 접속하기

##### putty로 접속하기

#### 2.1.3 인스턴스에 자바 설치

#### 2.1.4 주키퍼·카프카 브로커 실행

##### 카프카 브로커 힙 메모리 설정

##### 카프카 브로커 실행 옵션 설정

##### 주키퍼 실행

##### 카프카 브로커 실행 및 로그 확인

#### 2.1.5 로컬 컴퓨터에서 카프카와 통신 확인

##### 테스트 편의를 위한 hosts 설정

### 2.2 카프카 커맨드 라인 툴

#### 2.2.1 kafka-topics.sh

##### 토픽 생성

##### 토픽 리스트 조회

##### 토픽 상세 조회

##### 토픽 옵션 수정

#### 2.2.2 kafka-console-producer.sh

#### 2.2.3 kafka-console-consumer.sh

#### 2.2.4 kafka-consumer-groups.sh

#### 2.2.5 kafka-verifiable-producer, consumer.sh

#### 2.2.6 kafka-delete-records.sh

### 2.3 정리

## 3장 카프카 기본 개념 설명

### 3.1 카프카 브로커 · 클러스터 · 주키퍼

#### 데이터 저장, 전송

#### 데이터 복제, 싱크

#### 컨트롤러(controller)

#### 데이터 삭제

#### 컨슈머 오프셋 저장

#### 코디네이터(coordinator)

### 3.2 토픽과 파티션

#### 토픽 이름 제약 조건

#### 의미 있는 토픽 이름 작명 방법

### 3.3 레코드

### 3.4 카프카 클라이언트

#### 3.4.1 프로듀서 API

##### 카프카 프로듀서 프로젝트 생성

##### 프로듀서 중요 개념

##### 프로듀서 주요 옵션

##### 메시지 키를 가진 데이터를 전송하는 프로듀서

##### 커스텀 파티셔너를 가지는 프로듀서

##### 브로커 정상 전송 여부를 확인하는 프로듀서

#### 3.4.2 컨슈머 API

##### 카프카 컨슈머 프로젝트 생성

##### 컨슈머 중요 개념

##### 컨슈머 주요 옵션

##### 동기 오프셋 커밋

##### 비동기 오프셋 커밋

##### 리밸런스 리스너를 가진 컨슈머

##### 파티션 할당 컨슈머

##### 컨슈머에 할당된 파티션 확인 방법

##### 컨슈머의 안전한 종료

#### 3.4.3 어드민 API

##### 브로커 정보 조회

##### 토픽 정보 조회

### 3.5 카프카 스트림즈

#### 3.5.1 스트림즈DSL

##### KStream

##### KTable

##### GlobalKTable

##### 스트림즈DSL 주요 옵션

##### 스트림즈DSL - stream(), to()

##### 스트림즈DSL - filter()

##### 스트림즈DSL - KTable과 KStream을 join()

##### 스트림즈DSL - GlobalKTable과 KStream을 join()

#### 3.5.2 프로세서 API

### 3.6 카프카 커넥트

#### 커넥트를 실행하는 방법

#### 단일 모드 커넥트

#### 분산 모드 커넥트

#### 3.6.1 소스 커넥터

##### 파일 소스 커넥터 구현

#### 3.6.2 싱크 커넥터

##### 파일 싱크 커넥터 구현

### 3.7 카프카 미러메이커2

#### 3.7.1 미러메이커2를 활용한 지리적 복제(Geo-Replication)

### 3.8 정리
